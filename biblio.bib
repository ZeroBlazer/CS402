@article{Sipiran2011,
abstract = {With the increasing amount of 3D data and the ability of capture devices$\backslash$nto produce low-cost multimedia data, the capability to select relevant$\backslash$ninformation has become an interesting research field. In 3D objects,$\backslash$nthe aim is to detect a few salient structures which can be used,$\backslash$ninstead of the whole object, for applications like object registration,$\backslash$nretrieval, and mesh simplification. In this paper, we present an$\backslash$ninterest points detector for 3D objects based on Harris operator,$\backslash$nwhich has been used with good results in computer vision applications.$\backslash$nWe propose an adaptive technique to determine the neighborhood of$\backslash$na vertex, over which the Harris response on that vertex is calculated.$\backslash$nOur method is robust to several transformations, which can be seen$\backslash$nin the high repeatability values obtained using the SHREC feature$\backslash$ndetection and description benchmark. In addition, we show that Harris$\backslash$n3D outperforms the results obtained by recent effective techniques$\backslash$nsuch as Heat Kernel Signatures.},
author = {Sipiran, Ivan and Bustos, Benjamin},
doi = {10.1007/s00371-011-0610-y},
file = {:D$\backslash$:/rustycode/Documents/Papers/Interest Points/SB11b.pdf:pdf},
isbn = {0178-2789
1432-2315},
issn = {01782789},
journal = {Visual Computer},
keywords = {3D interest points detection,Harris operator,Local features},
number = {11},
pages = {963--976},
title = {{Harris 3D: A robust extension of the Harris operator for interest point detection on 3D meshes}},
volume = {27},
year = {2011}
}

@article{Lin2016,
abstract = {Researchers have proposed various methods to extract 3D keypoints from the surface of 3D mesh models over the last decades, but most of them are based on geometric methods, which lack enough flexibility to meet the requirements for various applications. In this paper, we propose a new method on the basis of deep learning by formulating the 3D keypoint detection as a regression problem using deep neural network (DNN) with sparse autoencoder (SAE) as our regression model. Both local information and global information of a 3D mesh model in multi-scale space are fully utilized to detect whether a vertex is a keypoint or not. SAE can effectively extract the internal structure of these two kinds of information and formulate high-level features for them, which is beneficial to the regression model. Three SAEs are used to formulate the hidden layers of the DNN and then a logistic regression layer is trained to process the high-level features produced in the third SAE. Numerical experiments show that the proposed DNN based 3D keypoint detection algorithm outperforms current five state-of-the-art methods for various 3D mesh models.},
archivePrefix = {arXiv},
arxivId = {1605.00129},
author = {Lin, Xinyu and Zhu, Ce and Zhang, Qian and Liu, Yipeng},
eprint = {1605.00129},
file = {:D$\backslash$:/rustycode/Documents/Papers/Interest Points/1605.00129v1.pdf:pdf},
keywords = {3d computer vision,3d keypoint detection,deep neural network,sparse au-},
pages = {1--13},
title = {{3D Keypoint Detection Based on Deep Neural Network with Sparse Autoencoder}},
url = {http://arxiv.org/abs/1605.00129},
year = {2016}
}

@article{Teran2014,
abstract = {The task of detecting the interest points in 3D meshes has typically been handled by geometric methods. These methods, while greatly describing human preference, can be ill-equipped for handling the variety and subjectivity in human responses. Different tasks have different requirements for interest point detection; some tasks may necessitate high precision while other tasks may require high recall. Sometimes points with high curvature may be desirable, while in other cases high curvature may be an indication of noise. Geometric methods lack the required flexibility to adapt to such changes. As a consequence, interest point detection seems to be well suited for machine learning methods that can be trained to match the criteria applied on the annotated training data. In this paper, we formulate interest point detection as a supervised binary classification problem using a random forest as our classifier. Among other challenges, we are faced with an imbalanced learning problem due to the substantial difference in the priors between interest and non-interest points. We address this by re-sampling the training set. We validate the accuracy of our method and compare our results to those of five state of the art methods on a new, standard benchmark.},
archivePrefix = {arXiv},
arxivId = {arXiv:1312.6826v1},
author = {Teran, Leizer and Mordohai, Philippos},
doi = {10.1007/978-3-319-10590-1_11},
eprint = {arXiv:1312.6826v1},
file = {:D$\backslash$:/rustycode/Documents/Papers/Interest Points/1312.6826.pdf:pdf},
isbn = {978-3-319-10589-5},
journal = {Eccv},
keywords = {3d computer vision},
pages = {1--8},
title = {{3D Interest Point Detection via Discriminative Learning}},
url = {http://dx.doi.org/10.1007/978-3-319-10590-1{\_}11},
year = {2014}
}

@article{Le2013,
author = {Le, Quoc V},
file = {:D$\backslash$:/rustycode/Downloads/unsupervised{\_}icml2012.pdf:pdf},
isbn = {9781479903566},
keywords = {unsupervised learning, deep learning},
pages = {8595--8598},
title = {{Building High-Level Features Using Large Scale Unsupervised Learning}},
year = {2013}
}

@article{Lin2016SparseRefinement,
abstract = {Three dimensional (3D) interest point detection plays a fundamental role in computer vision. In this paper, we introduce a new method for detecting 3D interest points of 3D mesh models based on geometric measures and sparse refinement (GMSR). The key point of our approach is to calculate the 3D saliency measure using two novel geometric measures, which are defined in multi-scale space to effectively distinguish 3D interest points from edges and flat areas. Those points with local maxima of 3D saliency measure are selected as the candidates of 3D interest points. Finally, we utilize an {\$}l{\_}0{\$} norm based optimization method to refine the candidates of 3D interest points by constraining the number of 3D interest points. Numerical experiments show that the proposed GMSR based 3D interest point detector outperforms current six state-of-the-art methods for different kinds of 3D mesh models.},
archivePrefix = {arXiv},
arxivId = {1604.08806},
author = {Lin, Xinyu and Zhu, Ce and Zhang, Qian and Liu, Yipeng},
eprint = {1604.08806},
file = {:D$\backslash$:/rustycode/Documents/Papers/Interest Points/1604.08806v1.pdf:pdf},
keywords = {3d computer vision,3d interest point detection,geometric properties of local,scale space,sparse refinement,surface},
pages = {1--9},
title = {{3D Interest Point Detection Based on Geometric Measures and Sparse Refinement}},
url = {http://arxiv.org/abs/1604.08806},
year = {2016}
}

@inproceedings{garstka2015fast,
  title={Fast and robust keypoint detection in unstructured 3-D point clouds},
  author={Garstka, Jens and Peters, Gabriele},
  booktitle={Informatics in Control, Automation and Robotics (ICINCO), 2015 12th International Conference on},
  volume={2},
  pages={131--140},
  year={2015},
  organization={IEEE}
}

@inproceedings{flint2007thrift,
  title={Thrift: Local 3D Structure Recognition.},
  author={Flint, Alex and Dick, Anthony R and Van Den Hengel, Anton},
  booktitle={dicta},
  volume={7},
  pages={182--188},
  year={2007}
}

@article{mian2010repeatability,
  title={On the repeatability and quality of keypoints for local feature-based 3d object retrieval from cluttered scenes},
  author={Mian, Ajmal and Bennamoun, Mohammed and Owens, Robyn},
  journal={International Journal of Computer Vision},
  volume={89},
  number={2-3},
  pages={348--361},
  year={2010},
  publisher={Springer}
}

@article{Lee2005,
abstract = {Research over the last decade has built a solid mathematical foundation for representation and analysis of 3D meshes in graphics and geometric modeling. Much of this work however does not explicitly incorporate models of low-level human visual attention. In this paper we introduce the idea of mesh saliency as a measure of regional importance for graphics meshes. Our notion of saliency is inspired by low-level human visual system cues. We define mesh saliency in a scale-dependent manner using a center-surround operator on Gaussian-weighted mean curvatures. We observe that such a definition of mesh saliency is able to capture what most would classify as visually interesting regions on a mesh. The human-perception-inspired importance measure computed by our mesh saliency operator results in more visually pleasing results in processing and viewing of 3D meshes. compared to using a purely geometric measure of shape. such as curvature. We discuss how mesh saliency can be incorporated in graphics applications such as mesh simplification and viewpoint selection and present examples that show visually appealing results from using mesh saliency.},
author = {Lee, Chang Ha and Varshney, Amitabh and Jacobs, David W.},
doi = {10.1145/1073204.1073244},
file = {:C$\backslash$:/Users/rustycode/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee, Varshney, Jacobs - 2005 - Mesh saliency.pdf:pdf;:D$\backslash$:/rustycode/Documents/Papers/Interest Points/mesh{\_}saliency{\_}sig05.pdf:pdf},
isbn = {07300301},
issn = {07300301},
journal = {ACM Transactions on Graphics},
keywords = {perception,saliency,simplification,visual attention},
number = {3},
pages = {659},
title = {{Mesh saliency}},
url = {http://dl.acm.org/citation.cfm?id=1073244},
volume = {24},
year = {2005}
}

@inproceedings{sun2009concise,
  title={A Concise and Provably Informative Multi-Scale Signature Based on Heat Diffusion},
  author={Sun, Jian and Ovsjanikov, Maks and Guibas, Leonidas},
  booktitle={Computer graphics forum},
  volume={28},
  number={5},
  pages={1383--1392},
  year={2009},
  organization={Wiley Online Library}
}

@article{Ng2011,
abstract = {Beschreibt Neuronale Netze, Backpropagation und (Sparse) Auto-Encoders},
archivePrefix = {arXiv},
arxivId = {arXiv:1506.03733v1},
author = {Ng, Andrew},
doi = {10.1371/journal.pone.0006098},
eprint = {arXiv:1506.03733v1},
file = {:D$\backslash$:/rustycode/Downloads/sparseAutoencoder{\_}2011new.pdf:pdf},
isbn = {1595937935},
issn = {19326203},
journal = {CS294A Lecture notes},
pages = {1--19},
pmid = {19568420},
title = {{Sparse autoencoder}},
url = {http://www.stanford.edu/class/cs294a/sae/sparseAutoencoderNotes.pdf},
year = {2011}
}
