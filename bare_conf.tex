
%% bare_conf.tex
%% V1.4b
%% 2015/08/26
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8b or later) with an IEEE
%% conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/pkg/ieeetran
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall the IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%*************************************************************************


% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. The IEEE's font choices and paper sizes can   ***
% *** trigger bugs that do not appear when using other class files.       ***                          ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



\documentclass[conference]{IEEEtran}
% Some Computer Society conferences also require the compsoc mode option,
% but others use the standard conference format.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference]{../sty/IEEEtran}





% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/pkg/ifpdf
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
%\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of the IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off
% such as if a citation ever needs to be enclosed in parenthesis.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 5.0 (2009-03-20) and later if using hyperref.sty.
% The latest version can be obtained at:
% http://www.ctan.org/pkg/cite
% The documentation is contained in the cite.sty file itself.






% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.PNG}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/pkg/graphicx
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/pkg/epslatex
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .PNG and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .PNG). The IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
%\usepackage{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics.
%
% Note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/amsmath





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as the IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/pkg/algorithms
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/pkg/algorithmicx




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/array


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
%  \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
%\else
%  \usepackage[caption=false,font=footnotesize]{subfig}
%\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a larger sans serif font
% than the serif footnote size font used in traditional IEEE formatting
% and thus the need to invoke different subfig.sty package options depending
% on whether compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/pkg/subfig




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure.
% Be aware that LaTeX2e kernels dated 2015 and later have fixltx2e.sty's
% corrections already built into the system in which case a warning will
% be issued if an attempt is made to load fixltx2e.sty as it is no longer
% needed.
% The latest version and documentation can be found at:
% http://www.ctan.org/pkg/fixltx2e


%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/stfloats
% Do not use the stfloats baselinefloat ability as the IEEE does not allow
% \baselineskip to stretch. Authors submitting work to the IEEE should note
% that the IEEE rarely uses double column equations and that authors should try
% to avoid such use. Do not be tempted to use the cuted.sty or midfloat.sty
% packages (also by Sigitas Tolusis) as the IEEE does not format its papers in
% such ways.
% Do not attempt to use stfloats with fixltx2e as they are incompatible.
% Instead, use Morten Hogholm'a dblfloatfix which combines the features
% of both fixltx2e and stfloats:
%
% \usepackage{dblfloatfix}
% The latest version can be found at:
% http://www.ctan.org/pkg/dblfloatfix




% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/url
% Basically, \url{my_url_here}.




% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{bm}
\usepackage{amsmath}

\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{Detección de puntos de interés\\en objetos 3D}


% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{\IEEEauthorblockN{Elías J. Puma}
\IEEEauthorblockA{Escuela profesional de\\Ciencias de la Computación\\
Universidad Nacional de San Agustín\\
Arequipa, Perú\\
Email: eliasj.puma@gmail.com}
}

% conference papers do not typically use \thanks and this command
% is locked out in conference mode. If really needed, such as for
% the acknowledgment of grants, issue a \IEEEoverridecommandlockouts
% after \documentclass

% for over three affiliations, or if they all won't fit within the width
% of the page, use this alternative format:
% 
%\author{\IEEEauthorblockN{Michael Shell\IEEEauthorrefmark{1},
%Homer Simpson\IEEEauthorrefmark{2},
%James Kirk\IEEEauthorrefmark{3}, 
%Montgomery Scott\IEEEauthorrefmark{3} and
%Eldon Tyrell\IEEEauthorrefmark{4}}
%\IEEEauthorblockA{\IEEEauthorrefmark{1}School of Electrical and Computer Engineering\\
%Georgia Institute of Technology,
%Atlanta, Georgia 30332--0250\\ Email: see http://www.michaelshell.org/contact.html}
%\IEEEauthorblockA{\IEEEauthorrefmark{2}Twentieth Century Fox, Springfield, USA\\
%Email: homer@thesimpsons.com}
%\IEEEauthorblockA{\IEEEauthorrefmark{3}Starfleet Academy, San Francisco, California 96678-2391\\
%Telephone: (800) 555--1212, Fax: (888) 555--1212}
%\IEEEauthorblockA{\IEEEauthorrefmark{4}Tyrell Inc., 123 Replicant Street, Los Angeles, California 90210--4321}}




% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract
\begin{abstract}
La detección de puntos de interés 3D juega un papel fundamental en el área de la Visión Computacional, la detección de estos puntos salientes en las superficies locales del objeto son importantes para poder realizar el procesamiento del objeto sin necesidad de procesar todos los puntos que lo conforman. En los papers descritos en este compendio se proponen ténicas que se basan sobre el análisis de las vecindades de los nodos, una utilizando el operador Harris en un modelo adaptado al espacio tridimensional y otra analizando las propiedades geométricas de cada sub-superficie del objeto. Además se incluyen dos técnicas de \textit{Machine Learning} que afirman no estar limitadas sólo por las propiedades geométricas. Dichos algoritmos demuestran ser efectivos al encontrar dichos puntos de interés y eficientes comparados a los algoritmos de referencia en el estado del arte.
\end{abstract}

% no keywords




% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introducción}
% no \IEEEPARstart
Muchas áreas son beneficiadas por las diferentes aplicaciones que se dan a los modelos 3D en las mismas. Mientras los modelos son más detallados y por ende más complejos el beneficio para estas áreas es aún mayor, por eso es necesario desarrollar también algoritmos que detecten los rasgos en estos modelos, esto hace que tareas como el registro, la recuperación y comparación de similitud de objetos, la simplicación de mallas y otras, sean facilitadas. Sin embargo, la detección de los puntos de interés es difícil porque en los modelos 3D sólo se cuentan con el conjunto de vértices y la conectividad que hay entre ellos, por ello se desarrollaron los métodos que se hallan aquí.

Para la tarea de detección de puntos de interpes usualmente se han utilizado métodos geométricos. Los métodos geométricos se basan en la alta curvatura de una superficie para determinar si un vértice es o no un punto de interés, pero en algunos casos esta característica implica la presencia de ruido en la superficie. Es por ello que un método basado en \textit{Machine Learning} puede tomar ventaja de esto frente a un método geométrico.

\subsection{Puntos de interés}
Acerca de qué es un punto de interés no hay alguna definición, el nivel de protusión o prominencia son claves en algunos métodos para hallarlos, así las superficies planas o casi planas de un objeto no son puntos de interés, como tampoco lo son las aristas de un objeto. Su principal característica es que sin importar si el objeto ha sufrido transformaciones los puntos de interés deberían mantenerse iguales.

\subsection{Características de un detector de puntos de interés}
La calidad de un detector de puntos de interés es principalmente medido por:

\begin{itemize}
	\item Su invariación a las transformaciones afines.
	\item Su robustez al ruido, que puede haber sido producido en el momento de captura.
	\item Su robustez a diferentes texturas en el objeto.
\end{itemize}

Todos los métodos explicados aquí muestran estas características a través de los resultados aplicados en sus respectivos benchmarks.

\subsection{K-rings}
Un vértice puede tener un número arbitrario de vértices vecinos. Definimos a k-ring como un conjunto de vértices, de los cuales la distancia mínima para llegar al vértice de referencia es de k. Como se ve en Fig.~\ref{fig:k_rings}, el número de vértices es diferente en cada nivel de k.

\begin{figure}
\includegraphics[width=1\linewidth]{k_neighbors.PNG}
\caption{Vértice $v$ y sus anillos de vecindad. $V_{1}(v)$: puntos azules; $V_{2}(v)$: puntos magenta; $V_{3}(v)$: puntos verdes, $V_{4}(v)$: puntos cian \cite{gmsr}}
\label{fig:k_rings}
\end{figure}


% This demo file is intended to serve as a ``starter file''
% for IEEE conference papers produced under \LaTeX\ using
% IEEEtran.cls version 1.8b and later.
% % You must have at least 2 lines in the paragraph with the drop letter
% % (should never be an issue)
% I wish you the best of success.

% \hfill mds
 
% \hfill August 26, 2015




% \subsubsection{Subsubsection Heading Here}
% Subsubsection text here.


% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%
%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure}

% Note that the IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command,
% and the \label for the overall figure must come after \caption.
% \hfil is used as a separator to get equal spacing.
% Watch out that the combined width of all the subfigures on a 
% line do not exceed the text width or a line break will occur.
%
%\begin{figure*}[!t]
%\centering
%\subfloat[Case I]{\includegraphics[width=2.5in]{box}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{box}%
%\label{fig_second_case}}
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat[]), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.
% Be aware that for subfig.sty to generate the (a), (b), etc., subfigure
% labels, the optional argument to \subfloat must be present. If a
% subcaption is not desired, just leave its contents blank,
% e.g., \subfloat[].


% An example of a floating table. Note that, for IEEE style tables, the
% \caption command should come BEFORE the table and, given that table
% captions serve much like titles, are usually capitalized except for words
% such as a, an, and, as, at, but, by, for, in, nor, of, on, or, the, to
% and up, which are usually not capitalized unless they are the first or
% last word of the caption. Table text will default to \footnotesize as
% the IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}


% Note that the IEEE does not put floats in the very first column
% - or typically anywhere on the first page for that matter. Also,
% in-text middle ("here") positioning is typically not used, but it
% is allowed and encouraged for Computer Society conferences (but
% not Computer Society journals). Most IEEE journals/conferences use
% top floats exclusively. 
% Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the
% \fnbelowfloat command of the stfloats package.




\section{Métodos}
A continuación se presentarán cuatro métodos para la detección de 3D \textit{keypoints}, los dos primeros basados en métodos geométricos y los dos siguientes basados en \textit{machine learning}.

\subsection{Harris 3D}
Harris y Stephens propusieron en 1988 una técnica para detectar los puntos de interés en una imagen \cite{corner}, Sipiran y Bustos han tomado la tarea de traducir el mismo método a un espacio discreto -ya que las mallas 3D sólo son puntos discretos en el espacio y el operador Harris utiliza derivadas- y llevar un modelo de selección de los vértices de interés utilizando el valor de Harris como principal discriminador, también para mitigar el efecto del ruido y de los agujeros en los objetos utilizaron una función Gaussiana para suavizar su superficie.

Dado un vértice en un objeto 3D, se calcula del valor del operador Harris asociado a ese punto. Sea $v$ nuestro vértice y $V_{k}(v)$ los k-rings del vecindario del vértice. Se calcula el centroide de $V_{k}(v)$ y se traslada el conjunto de puntos al origen del plano 3D de coordenadas. Para ello se aplica el análisis del componente principal al conjunto de puntos y se escoge el eigenvector con el menor valor asociado a la normal del plano ajustado. El conjunto de puntos es rotado para que quede sobre el eje $z$, los puntos son trasladados nuevamente de manera que $v$ es el origen del plano $XY$ y luego se calcularán las derivadas.

Para calcular las derivadas, se ajusta una superficie cuadrática al conjunto de puntos transformados. Utilizando el método de mínimos cuadrados se encuentra un paraboloide de la forma:

\begin{equation}
z = f(x,y) = \frac{p_{1}}{2} x^{2} + p_{2}xy + \frac{p_{3}}{2} y^{2} + p_{4}x + p_{5}y + p_{6}
\end{equation}

Las derivadas del punto $v$ pueden ser evaluadas directamente y también aplicar una función Gaussiana para reducir los efectos que el ruido pueda tener. Para realizar eso la función continua Gaussiana puede ser aplicada de la siguiente manera:

\begin{equation}
A = \frac{1}{\sqrt{2\pi}\sigma}\int_{R^{2}} e^{\frac{-(x^{2}+y^{2}}{2\sigma^{2}}}.f_{x}(x,y)^2 dx dy
\end{equation}

\begin{equation}
B = \frac{1}{\sqrt{2\pi}\sigma}\int_{R^{2}} e^{\frac{-(x^{2}+y^{2}}{2\sigma^{2}}}.f_{y}(x,y)^2 dx dy
\end{equation}

\begin{equation}
C = \frac{1}{\sqrt{2\pi}\sigma}\int_{R^{2}} e^{\frac{-(x^{2}+y^{2}}{2\sigma^{2}}}.f_{x}(x,y).f_{y}(x,y) dx dy
\end{equation}

Finalmente, la matrix $E$ es la que asocia los valores previos calculados:

\[ E = \left( \begin{array}{cc}
A & C \\
C & B \end{array} \right)\]

y el valor Harris es:

\begin{equation}
h(x,y)=det(E)-k.(tr(E))^{2}
\end{equation}

\subsection{Geometric Measures and Sparse Refinement}
La técnica propuesta por Lin, Zhu, Zhang y Liu se basa en crear un plano tangencial para los vértices del objeto 3D, a través de un filtro Gaussiano que se basa en el trabajo de C. Ha Lee, A. Varshney y D. W. Jacobs \cite{mesh saliency} se obtienen superficies con alta protusión, dentro de éstas se segmentan vecindades, y en los vértices pertenecientes a estas vecindades se calcula un plano tangente a través de la normal del mismo, se calcula un valor discriminatorio mediante la distancia de los vértices pertenecientes a las cuatro primeras k vecindades del vértice y a través del producto armónico de los vectores normales de estos, esto permite reconocer los vértices en los que hay mucha prominencia y también reconocer si estamos en las aristas (bordes) de un objeto sólido.

\subsubsection{La distancia de un anillo de vecindad a un plano tangente}
Debido a que un número arbitrario dde vértices vecinos pueden existir alrededor de un vértice $v$, se utiliza el promedio armónico de la distancia de los k-rings al plano tangente en vez de una suma de las distancias. $n$ es el vector normal, la manera para obtener el plano normal es:

\[n^{T}[x-x_{v}, y-y_{v}, z-z_{v}]^{T}\]

Entonces el promedio armónico será:

\begin{equation}
	\bar{d} = \prod_{k=1}^{4} \bar{d_{k}}
\end{equation}

\begin{equation}
	\bar{d_{k}} = \frac{W_{k}}{\sum_{j=1}^{W_{k}} \frac{1}{d_{kj}}}
\end{equation}

\begin{equation} \label{eq:dkj}
	d_{kj} = \frac{|\bm{n}^{T}[x_{kj}, y_{kj}, z_{kj}]^{T} - \bm{n}^{T}[x_{v}, y_{v}, z_{v}]^{T}|}{\|\bm{n}\|_{2}}
\end{equation}

El usar el promedio armónico también distingue los puntos de interés 3D de los bordes en cierta medida.

\subsubsection{Mínimo ángulo de vectores normales entre un vértice y su primer anillo}
Junto con la propiedad mencionada arriba, la siguiente nos permite llegar más lejos en la distinción de los puntos de interés 3D de los bordes, ésta es el de el mínimo angulo de vectores normales entre un vértice y su primer anillo, que puede ser formulado como:

% \begin{figure}[here]
% \centering
% \includegraphics[width=1\linewidth]{minimun_angle.PNG}
% \end{figure}

\begin{equation} \label{eq:teta}
	\theta = min(arccos(\frac{\bm{n}^{T}\bm{n}_{f}}{\|\bm{n}\|_{2}\|\bm{n}_{f}\|_{2}}))
\end{equation}

% \subsubsection{La distancia de un anillo de vecindad a un plano tangente}

\subsection{Random Forest}
Para el entrenamiento de la red neuronal se utilizan los siguientes atributos como entradas:

\subsubsection{Atributos básicos}
Cada vértice tiene un total de 43 atributos, en los cuales hay dos clases de atributos: Los básicos (10 atributos que incluyen: radios de los eigenvalores de una subsuperficie, diferencia entre los mismos y su curvatura gaussiana), y los derivados de la Diferencia de Gaussianos (33 atributos).

\subsubsection{Random Forest}
Son árboles de decisiones que bajo el entrenamiento que han recibido pueden segmentar los datos de entrenamiento según las etiquetas que tienen: Si son o no \textit{key points}, etc. Cada nodo genera pruebas aleatorias para el entrenamiento de los árboles. Después del entrenamiento el árbol podrá clasificar los datos de entrada de acuerdo a las clases con las que fue entrenado.

\subsubsection{Clases Imbalanceadas}
El método de 3D Interest Point Detection via Discriminative Learning hizo que un grupo de personas seleccione los puntos de interés en varios modelos, no todos ellos estaban en una protución en el objeto. A partir del punto seleccionado se determina un radio para una región de interés. por medio de los parámentros $\sigma$ y $n$, $\sigma$ definido por el usuario.

\subsubsection{\textit{Ground truth}}
Cuando se tomaron las muestras de los clicks de los usuarios las posiciones de los puntos de interés tenían una variación presente, podía ser dado por la impresición del hacer click o del interés subjetivo de los mismos, de acuerdo al método de Chen referenciado en \cite{forest}. Dicho método consideraba un radio $\sigma d_{M}$ de una región de interés y el número $n$ de clicks que se habían dado allí. Cada uno de los clicks fue clusterizado junto a otros si sus distancias fueron menores que $2 \sigma d_{M}$. Cuando el número de clicks en un cluster fue menor que $n$ el cluster fue ignorado. En el caso contrario el punto que minimiza su distancia geodésica con respecto a los demás puntos fue tomado como el punto representativo.

\subsubsection{Clases imbalanceadas}
Una de las dificultades presentes en los clasificadores son la presencia de clases imbalanceadas, en donde hay una clase que es dominante frente a las demás clases. Para lidiar con esto los autores utilizan una técnica propuesta por Chen en donde a la clase dominante se le disminuye en elementos para el entrenamiento mientras que a las clases minoritarias se les aumenta en elementos para el entrenamiento. Para un conjunto de vértice, se selecciona aleatoriamente $n$ puntos de interés, donde $n$ es la mitad del número total de puntos de interés. Mientras cada árbol es entrenado se tiene un radio de $k$ puntos que no son de interés que corresponden a $n$ puntos de interés. $k \geq n$. El parámetro $k$ se discute más adelante.

\subsection{Deep Neural Network}

\begin{figure}
\includegraphics[width=1\linewidth]{DNN_diagram.eps}
\caption{Izquierda: esquema de un autoencoder. Derecha: DNN con tres SAEs como capas ocultas y una capa de regresión logística \cite{dnn}}
\label{fig:DNN_diagram}
\end{figure}

\subsubsection{\textit{Sparse Autoencoder}}
Al lado izquierdo de la Figura~\ref{fig:DNN_diagram} se ha graficado la estructura de un autoencoder, un autoencoder es un algoritmo de aprendizaje sin supervisión en la que los valores objetivos son iguales a los objetos de entrada. Puede aprender una representación dimensionalmente baja de los datos de entrada al limitar el número de unidades escondidas.

Un \textit{Sparse autoencoder} es una variante del \textit{autoencoder}, que se puede realizar al imponer restricción de escacez en las unidades escondidas. Puede también aprender la estructura de interés de los datos de entrada, incluso si la dimensión de la capa oculta es mayor que la dimensión de la capa de entrada. Su costo general es:

\begin{equation}
  J_{sparse}(W, b) = \frac{1}{2} \|h_{W, b}-x\|^{2} + \beta \sum_{j=1}^{S}{KL(\rho\|\hat{\rho}_{j})}
\end{equation}

\subsubsection{\textit{Deep Neural Network} con \textit{Sparse Autoencoder}}
Las Redes Neuronales son muy útiles para la clasificación y regresión de problemas con datos complejos. El problema reside en que las redes que tienen muchas capas ocultas podrían presentar problemas para ser entrenadas debido al problema mínimo de pesos. 
Para el paper se utilizó el modelo SAE, por su habilidad para el procesamiento de características en los datos de entrada. Utilizar un \textit{deep sparse autoencoder} (DSAE, un conjunto de SAEs) puede aprender altos niveles de características efectivamente. Cada SAE en el DSAE puede aprender características en diferentes niveles, lo que también permite que la DNN tenga un pre-entrenamiento (los pesos iniciales serán próximos al óptimo).
Para formular el modelo de regresión DNN primero se entrenan los tres SAEs y se selecciona la parte del encoder para formular las capas ocultas de la DNN: Las primeras capas irán entrenando a su siguiente capa.

\subsubsection{Atributos y el proceso de entrenamiento}
Para modelos 3D de mallas, no otra información sino la posición de vértices y su conectividad entre éstos. Si tenemos suficientes modelos 3D con \textit{key-points} verificados pueden ser utilizados para entrenar el modelo descrito, para poder mejorar este proceso se puede pre-procesar la información de los datos originales para definir atributos de entrada para realizar la regresión en la Red Neuronal Profunda.

\paragraph{Atributos}
Para el método se utilizaron tanto información local (con respecto a un vértice) e información global para definir los atributos para las entradas de la \textit{DNN}. La información local describe tres tipos de propiedades geométricas de la superficie de un modelo: (1) la distancia Euclídea entre los anillos vecinos y el plano tangente al vértice, (2) los ángulos de los vectores normales entre el vértice y los anillos vecinos, (3) varias curvaturas. Para la información global se consideraron las propiedades del espectro log-Laplaciano del modelo.

La información local puede ser representada como $ (\bm{f}_{d}, \bm{f}_{\theta}, \bm{f}_{c}) $, después de haber definido (\ref{eq:dkj}) y (\ref{eq:teta}) tendremos que:

\begin{equation}
\begin{split}
	\bm{f}_{d} = [max(\bm{d}_{k}), min(\bm{d}_{k}), max(\bm{d}_{k}) - min(\bm{d}_{k}),\\
		mean(\bm{d}_{k}),var(\bm{d}_{k}), harmmean(\bm{d}_{k})]
\end{split}
\end{equation}

\begin{equation}
\begin{split}
	\bm{f}_{\theta} = [max(\bm{\theta}_{k}), min(\bm{\theta}_{k}), max(\bm{\theta}_{k}) - min(\bm{\theta}_{k}),\\
		mean(\bm{\theta}_{k}),var(\bm{\theta}_{k}), harmmean(\bm{\theta}_{k})]
\end{split}
\end{equation}

donde $mean(\cdot)$, $var(\cdot)$ y $harmmean(\cdot)$ son el promedio aritmético, varianza y promedio harmónico respectivamente.

\begin{table*}[t]
\centering
\begin{tabular}{ccccccc}
\hline
&	$max(\cdot)$	&	$min(\cdot)$	&	$max(\cdot) - min(\cdot)$	&	$mean(\cdot)$	&	$var(\cdot)$	&	$harmmean(\cdot)$ \\
\cline{1-7}
Areas planas			&	pequeño	&	pequeño	&	pequeño	&	pequeño	&	pequeño	&	pequeño	\\
Bordes					&	grande	&	pequeño	&	grande	&	relativamente grande	&	grande	&	pequeño	\\
\textit{Keypoints 3D}	&	grande	&	grande	&	pequeño	&	grande	&	pequeño	&	grande	\\

\hline
\end{tabular}
\caption{El efecto de seis tipos de propiedades estadísticas presentadas en diferentes regiones de un modelo 3D \cite{dnn}}
\label{tbl:dnn_features}
\end{table*}

En la tabla \ref{tbl:dnn_features} se muestran los tipos de propiedades estadísticas que pueden presentarse en un modelo que nos dan una idea de la clase del entrenamiento que nuestra red recibirá.

Junto con ambas propiedades se incluye otra local: las curvaturas, en el paper se utilizaron cuatro tipos de curvaturas para formular $\bm{f}_{c}$ como:

\begin{equation}
\bm{f}_{c} = [c_{1}, c_{2}, \frac{c_{1} + c_{2}}{2}, c_{1}c_{2}]
\end{equation}

donde $c_{1}$ y $c_{2}$ son las curvaturas principales. $(c_{1} + c_{2})/2$ es la curvatura media y $c_{1}c_{2}$ la curvatura gaussiana.

Los atributos que se utilizan como información global depende del espectro Laplaciano, obtenido a partir de:

\begin{equation}
\bm{L} = \bm{B} \wedge \bm{B}^{T}
\end{equation}

\paragraph{Proceso de entrenamiento}
El entrenamiento se hizo con los mismos \textit{datasets} usados por otros autores con trabajos similares \cite{forest}: Un conjunto de dos datasets donde los \textit{keypoints} fueron seleccionados por un grupo de personas, un \textit{dataset} A con 24 modelos con \textit{keypoints} anotados por 16 personas y otro \textit{dataset} B constituido de 43 modelos anotados por 16 personas. Se utilizaron dos tercios de cada dataset para el entrenamiento de la red neuronal y el tercio restante como datos para las pruebas. 

Para entrenar el modelo se necesita entrenar primeramente los SAEs primeramente. La primera capa teniendo 665 entradas y 800 salidas con un $\rho$ de 0.15 y $\beta$ 4. El segundo con 800 entradas de entrenamiento y 200 salidas con el mismo $\rho$ y $\beta$ anterior. La tercera capa con 200 entradas y 50 salidas con $\rho$ de 0.1 y $\beta$ 4. Este entrenamiento se hace tomando en consideración que las tres SAEs son apiladas junto a una nueva capa logística que también será entrenada utlizando 50 datos de entrada tomados del SAE 3.

El proceso del entrenamiento de las tres SAEs y el de la capa logística puede verse como un pre-entrenamiento, y para mejorar su rendimiento un ajuste se hace por medio de \textit{backpropagation}.

\subsubsection{\textit{Algoritmo propuesto basado en \textit{DNN}}}
Básicamente el proceso para detectar un \textit{keypoint} con un modelo de DNN se puede dividir en cuatro pasos:

\begin{itemize}
\item Utilizar el filtro gaussiano para construir un Modelo $\bm{M}(x, y, z)$ escalado en el espacio y tomar una serie de modelos evolucionados $\bm{M}_{\delta}(x, y, z)$.
\item Utilizar la información multiescala para cada vértice del modelo 3D para calcular atributos (como en la subsección anterior).
\item Para cada vértice del modelo, colocar sus atributos como entradas de una \textit{DNN} y tomar el valor de regresión, luego obtener el \textit{saliency map} del modelo.
\item A partir de los \textit{saliency maps} obtener los máximos locales, comparar los valores $\rho$ retornados por la \textit{DNN} para cada vértice con aquellos que pertenecen a los anillos $V_{k}(v), k = 1, 2, 3, 4, 5$ y tomar el máximo como un \textit{keypoint}.
\end{itemize}

\section{Resultados de la experimentación}
Al igual que en la anterior sección dividiremos los resultados de acuerdo a la presentación de los mismos en cada método:

\subsection{Harris 3D}
Los autores utilizaron el benchmark SHREC como base de datos para medir el desempeño de su técnica, en ella hay objetos en su forma \textit{null} (sin transformaciones) así como con transformaciones de isometría, topología, agujeros grandes y pequeños, escalabilidad global y parcial, ruido Gaussiano y de disparo, y simplificación de la superficie.

Los valores de parámetros que se utilizaron fueron: El tipo y tamaño de la vecindad local, El parámetro K, el tipo del método de la selección de los puntos de interés. Los resultados se representan en niveles de fortaleza que se pueden ver en la Tabla ~\ref{fig:H3D_results}.

\begin{table}
\includegraphics[width=1\linewidth]{harris_table.eps}
\caption{Harris 3D vs. Heat Kernel Signature \cite{harris}}
\label{fig:H3D_results}
\end{table}

\subsection{Geometric Measures and Sparse Refinement}
En su método, ellos compararon los resultados del desempeño de los detectores de acuerdo a tres métricas: El error falso positivo (FPE), error falso negativo (FNE) y error de pérdida ponderada (WME) utilizando un benchmark de referencia por H. Dutagaci, C. P. Cheung, y A. Godil (\ref{eq:IOU}): 

\begin{equation} \label{eq:IOU}
IOU(r) = \frac{TP}{FN + FP + TP}
\end{equation}

Para su experimentación compararon sus resultados con seis diferentes algoritmos: HKS, 3D-SIFT, 3D-Harris, Mesh saliency, Salient-points y SD-corners. Los resultados han sido resumidos en la Fig.~\ref{fig:GMSR_results}.

\begin{figure}
\includegraphics[width=1\linewidth]{tables.eps}
\caption{Resultados de GMSR \cite{gmsr}}
\label{fig:GMSR_results}
\end{figure}

\subsection{Random Forest}
Los resultados se basan en dos datasets A y B bajo la métrica IOU, para alcanzar un ranking general se promedian sus valores bajo todas las configuraciones. Y esto da lugar a los siguientes resultados para así minimizar el promedio AUC: \textit{random forest} 0.02787; HKS 0.02390; \textit{Salient Points} 0.02295; 3D Harris 0.01915; SD \textit{Corners} 0.01438; \textit{Mesh Saliency} 0.01387. Repitiendo la misma operación para el \textit{dataset} B se obtuvo: \textit{random forest} 0.0279; \textit{Salient Points} 0.0236; HKS 0.0215; 3D Harris 0.0180; SD \textit{Corners} 0.0148; \textit{Mesh Saliency} 0.0137.

\subsection{Deep Neural Network}
Para realizar una comparación completa, se promedian los cuatro tipos de evaluación dados puntajes métricos sobre todas las configuraciones, la tabla~\ref{fig:DNN_results} muestra los promedios de IOU, FNE, FPE y WME con respecto a la tolerancia de error $r$ para seis algoritmos de detección en donde $n \in \{2, 3, ..., 23\} / \sigma \in \{0.01, 0.02, ..., 0.1\}$ para el \textit{dataset} A y $n \in \{2, 3, ..., 16\} / \sigma \in \{0.01, 0.02, ..., 0.1\}$ para el \textit{dataset} B.
\begin{table}
\includegraphics[width=1\linewidth]{dnn.eps}
\caption{Promedio de IOU, FNE, FPE, WME en el dataset de prueba A \cite{dnn}}
\label{fig:DNN_results}
\end{table}

\section{Conclusión}
La técnica presentada de la adaptación del operador Harris a los objetos 3D demostró ser una extensión efectiva y eficiente comparado con el método Heat Kernel Signature, en especial al ser robusto en la transformación de los objetos, la presencia de agujeros y de texturas de ruido.

En ambos métodos se nota una ventaja al usar las k-vecindades de un vértice para la discriminación de los puntos de no interés: En Harris 3D para poder obtener las derivadas de las trayectorias conectivas en los vértices, y en GMSR para poder distinguir los puntos en los que la trayectoria varía mucho en cuanto a su entorno. Vemos que el método GMSR muestra muy buenos resultados frente a otras técnicas (incluído Harris 3D), pero que compite de buena manera con Heat Kernel Signature que a veces tiene un mejor desempeño que él.

Tanto los métodos geométricos como los métodos basados en \textit{machine learning} presentan muy buenos resultados, evaluando los diferentes resultados podemos decir que los segundos son mejores pueden superar las desventajas de presentar falsos positivos que tienen los primeros. Principalmente el modelo propuesto basado en \textit{DNNs} demuestra que el aprendizaje de características en un autoencoder fundamenta el logro de sus buenos resultados.

% conference papers do not normally have an appendix


% use section* for acknowledgment
%\section*{Acknowledgment}


%The authors would like to thank...





% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://mirror.ctan.org/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
\begin{thebibliography}{1}

\bibitem{harris}
I. Sipiran y B. Bustos, \emph{Harris 3D: a robust extension of the Harris operator for interest point detection on 3D meshes}\hskip 1em plus
  0.5em minus 0.4em\relax Santiago, Chile: Springer, 2011.

\bibitem{gmsr}
X. Lin, C. Zhu, Q. Zhang y Y. Liu, \emph{3D Interest Point Detection Based on Geometric Measures
and Sparse Refinement}\hskip 1em plus
  0.5em minus 0.4em\relax Chengdu, China: UESTC, 2016.

\bibitem{robust3D}
I. Sipiran y B. Bustos, \emph{HA Robust 3D Interest Points Detector Based on Harris
Operator}\hskip 1em plus
  0.5em minus 0.4em\relax : Eurographics Workshop on 3D Object Retrieval, 2010.

\bibitem{corner}
C. Harris y M. Stephens, \emph{A Combined Corner and Edge Detector}\hskip 1em plus
  0.5em minus 0.4em\relax United Kingdom: Plessey Research Roke Manor, 1988.

\bibitem{mesh saliency}
C. Ha Lee, A. Varshney y D. W. Jacobs, \emph{Mesh Saliency}\hskip 1em plus
  0.5em minus 0.4em\relax Maryland, Estados Unidos: College Park.

\bibitem{forest}
L. Teran, P. Mordohai, \emph{3D Interest Point Detection via Discriminative
Learning}\hskip 1em plus
  0.5em minus 0.4em\relax Stevens Institute of Technology, EUA, 2013.

\bibitem{dnn}
X. Lin, C. Zhu, Q. Zhang y Y. Liu, \emph{3D Keypoint Detection Based on Deep Neural Network with
Sparse Autoencoder}\hskip 1em plus
  0.5em minus 0.4em\relax Chengdu, China: UESTC, 2016.

\end{thebibliography}




% that's all folks
\end{document}


