\documentclass{comjnl}

\usepackage{amsmath}

\begin{document}


\title[Modelling Bidders in Sequential Automated Auctions]{3D Keypoint detection with Deep Neural Networks}
\author{El\'{i}as J. Puma}
\affiliation{Escuela Profesional de Ciencia de la Computaci\'{o}n,\\
Universidad Nacional de San Agust\'{i}n,\\
Arequipa, PE}
\email{eliasj.puma@gmail.com}

\shortauthors{E. Puma}

%\received{00 January 2009}
%\revised{00 Month 2009}


%\category{C.2}{Computer Communication Networks}{Computer Networks}
%\category{C.4}{Performance of Systems}{Analytical Models}
%\category{G.3}{Stochastic Processes}{Queueing Systems}
%\terms{Internet Technologies, E-Commerce}
\keywords{Keypoint detection; Deep Neural Networks; 3D Model; Sparse Autoencoders}


\begin{abstract}
3D keypoint detection plays a fundamental role in the Computer Vision field, detection of these salient points in the local surfaces of a 3D object is important in order to perform certain tasks such as registration, retrieval and simplification. There has been a lot of research in the field of 3D keypoint detection, most of them take a geometrical approach which have a good performance but lack flexibility to adapt to changes such as noise and high curvature points that are not keypoints to human preference. A good approach seems to be machine learning methods that can be trained with human annotated training data. In this paper a new method is proposed using deep neural network with sparse autoencoder as the regression model due to their great ability for feature processing. The analysis shows this method would outperform other methods that are widely used.  
\end{abstract}

\maketitle


\section{Introduction}
Several computer-dependent areas are benefited of the applications
that 3D Models have in them. The growth of 3D data has increased in
the last years with the availability of low-cost 3D capture devices~\cite{harris3D}.
The ability to analyse, proccess and select relevant information
from them is an active research area. 

3D interest point detection is a difficult task for several reasons~\cite{Discrim, harris3D}. 
First, there are not any definitions for what a interest point is, 
most of the approaches consider the high level of protusion in a local
area as a keypoint characteristic. So, in planar sections of an area
vertices have a low interest level and in local areas with diferent
structures the interest level will be the opposite. Second, vertex 
density is different for every 3D model which makes harder the task of
selecting a local area. Third, information obtained from a 3D model
are only vertex positions and connectivity between them which means
the interest level will depend only from the information we can
retrieve from different calculations. These are not the only reasons
but are sufficient for explaining why this method is prepared to
handle these difficulties. 

The common approach to 3D keypoint detection has been to use 
geometric properties of the models, although in recent years researchers
also have developed machine learning techniques that try to outperform the
former one by avoiding the problems of: Different tasks in different areas
of the model~\cite{DNN}, false positives obtained from noise or local
variation and keypoint detection valuable according to human preference. 

The rest of this paper is organized in the following way:
Section~\ref{RelatedWork} introduces previous work done in the area,
Section~\ref{Proposal} presents the idea this method is based on. Future
results will be presented in Section~\ref{Results} and future conclusions
in Section~\ref{Conclusions}.

\section{Related Work} \label{RelatedWork}
In recent years researchers have proposed several techniques for
3D keypoint detection. Most of them are based on geometric methods, for
example Sipiran and Bustos extended the Harris operator for 3D
meshes~\cite{harris3D}. Lin, Zhu, Zhang and Liu proposed a geometric
technique~\cite{GMSR} based in the tangencial planes traced for each vertex and
other transformations in the mesh some of them can be also found
in~\cite{DNN}. 

\section{Proposal} \label{Proposal}
This work is inspired by the work of~\cite{DNN} by the use of
sparse autoencoders as the regression model in order to learn features
from local and global information generated from a human-annotated
keypoint database. Also this proposal is influenced by~\cite{UnsLearning},
so for us to achieve the 3D keypoint detection we train a 3-layered locally
connected sparse autoencoder similarly to their technique, such
technique's results revealed to be a inexpensive way to develop
high-level features from unlabeled data, from that study this work
presents an adapted architecture for 3D meshes. Taking a different approach
than the other techniques mentioned above, resized and simplified segments
of the 3D mesh will be used as the input for our Deep Neural Network,
this will enable our DNN to learn when one of these segments has inside
a keypoint.

\subsection{Architecture}
This technique can be seen as a set of sparse deep autoencoders that
similarly to~\cite{UnsLearning} has two fields in it: local receptive fields,
pooling normalization (the architecture taken as a base can be seen
on the Figure~\ref{fig:architecture}). Local receptive fields scale the
autoencoder to big inputs, connecting the autoencoder's features to a small
region of the next lower layer. These sublayers are know as filtering and
pooling.

Originally the neurons in the first sublayer were connected to
pixels in all input channels~\cite{UnsLearning}, but in order to adapt
this architecture it is proposed to use the 3D vertices and their
connectivity information as the input channels and by so adding more
receptive fields.

\begin{figure}
\includegraphics[width=0.9\linewidth]{architecture.png}
\caption{Large scale unsupervised learning architecture \cite{UnsLearning}}
\label{fig:architecture}
\end{figure}

\subsection{Training}
As mentioned before the first layer input...

To train the Deep Neural Network what is to be done at first is to train each
Sparse Autoencoder and a final logistic regression layer, then following the
schema from~\cite{DNN} stack the four layers together and backpropagate the
whole DNN to fine tune it.

The goal of this approach is to reduce the proccessing that is performed,
instead of evaluating each vertex in the DNN which is expensive, we can
perform the neccesary calculations just for some samples of the 3D object
and discard if those samples don't contain any keypoints, in the case we find
the presence of keypoints we will perform further calculations to choose the
sample keypoint.

\section{Results} \label{Results}

\section{Conclusions} \label{Conclusions}

\ack{This research was undertaken as part of ...}


\nocite{*}

\bibliographystyle{compj}
% \bibliography{ModellingBidders}
\input{sample.bbl}


\end{document}
